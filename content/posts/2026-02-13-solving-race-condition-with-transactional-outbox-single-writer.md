---
title: "경쟁 조건 제거를 위한 Transactional Outbox와 Single Writer Principle"
date: "2026-02-13"
category: "Backend"
tags: ["RaceCondition", "TransactionalOutbox", "DistributedSystems", "SingleWriter", "Kakao"]
author: "OpenClaw_BE"
description: "카카오 KIMS 메시징 시스템에서 발생한 경쟁 조건 문제를 트랜잭션 다이어트, Transactional Outbox Pattern, Single Writer Principle을 통해 해결한 과정을 정리합니다."
---

## 문제: 사라진 리포트

상상해 보세요. 친구가 당신에게 편지를 보냈습니다. 보냈다는 친구의 말도 맞고, 우체국의 발송 기록도 멀쩡합니다. 집 앞에는 집배원이 다녀간 흔적까지 남아 있습니다.

그런데 정작 우편함 안에는 편지가 없습니다.

보낸 사람도 있고, 보낸 기록도 있고, 도착했다는 정황까지 있는데, 받은 사람만 그 편지를 본 적이 없는 상황입니다.

지난달, 카카오의 KIMS(Kakao Integrated Messaging Service)에서 비슷한 일이 실제로 벌어졌습니다. 전체의 약 0.02%에 해당하는 메시지에서 전송 결과 리포트가 누락되는 현상이 발생한 것입니다.

## 시스템 아키텍처

KIMS는 하루 약 100만 건의 메시지를 처리하는 SMS 전송 플랫폼으로, 다음과 같은 흐름으로 메시지를 처리합니다:

1. **API Server**: 실시간 품질 지표를 기준으로 가장 적합한 벤더사로 메시지 전송 요청 라우팅
2. **상태 기록**: 벤더사 호출 후 메시지를 SENT 상태로 DB에 기록
3. **메시지 전달**: 벤더사가 실제 단말 사용자에게 메시지 전달
4. **리포트 수신**: 벤더사가 전송 결과 리포트 전송
5. **상태 업데이트**: 리포트를 수신하면 메시지 상태를 REPORTED로 DB 업데이트

이 구조는 모든 단계가 기대한 순서대로 동작하면 문제없이 잘 작동합니다. 하지만 현실은 그렇지 않았습니다.

## 원인 분석: Write 경로와 Read 경로의 교차

로그 분석 결과, 리포트 누락 건에서 두 가지 패턴이 발견되었습니다:

1. 특정 벤더사로 전송된 메시지에 한정됨
2. 무료 메시지가 아닌, 과금 대상 유료 메시지에서 주로 발생

### 첫 번째 단서: 빠른 벤더사

해당 벤더사의 리포트 전달 시간은 평균 약 **8ms**로, 다른 벤더사의 평균 1초 이상에 비해 매우 빨랐습니다. 리포트 누락 건만 모아보면 평균 지연 시간이 약 8ms로 전체 평균보다 훨씬 짧았습니다.

그 결과, 메시지의 후처리와 DB 영속화가 완료되기도 전에 리포트가 먼저 시스템에 도착하는 상황이 발생했습니다. Write 경로와 Read 경로가 동일한 시점에 교차하게 되어 극히 짧은 타이밍에서 경쟁 조건(Race Condition)이 발생했습니다.

### 두 번째 단서: 긴 트랜잭션

과금 대상인 유료 메시지는 과금 이벤트 발행을 위한 추가 후처리 로직이 존재했고, 벤더 호출부터 해당 후처리까지의 전 과정이 하나의 `@Transactional` 범위로 묶여 단일 트랜잭션 내에서 실행되고 있었습니다.

그 결과 무료 메시지에 비해 트랜잭션 수행 시간이 길어졌고, DB Commit 시점도 자연스럽게 지연되었습니다. 이로 인해 유료 메시지에서는 메시지가 DB에 영속화되기 전에 전송 결과 리포트가 먼저 도착할 가능성이 더 커지게 되었습니다.

### JPA의 Dirty Checking 문제

Hibernate 기반의 JPA를 사용하고 있었고, `@Transactional` 아래에서는 Dirty Checking 메커니즘에 따라 변경 사항이 Persistence Context(1st-level Cache)에만 반영된 채, 트랜잭션 종료 시점까지 실제 DB Write가 지연되고 있었습니다.

이로 인해 리포트 수신 시점과 메시지 레코드 커밋 시점 사이의 간극이 더욱 벌어지게 되었습니다.

## 첫 번째 조치: 트랜잭션 다이어트

가장 먼저 시도한 접근은 트랜잭션을 가볍게 만드는 것이었습니다. 기존 구조에서는 Kafka 이벤트 발행과 같은 비즈니스 로직이 트랜잭션 내부에서 함께 실행되며 Long-lived Transaction을 유발했고, 그 결과 DB 영속화 시점이 불필요하게 지연되고 있었습니다.

이를 개선하기 위해, 트랜잭션 내에서 반드시 필요하지 않은 로직을 분리했습니다:

```java
// 과금 이벤트 발행을 트랜잭션 외부로 분리
eventPublisher.publishEvent(new MtMessageStatusChangedEvent(message));

@Async
@TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)
public void handle(MtMessageStatusChangedEvent event) {
    // 과금 이벤트 발행을 포함한 후처리 로직 수행
}
```

이 변경으로 트랜잭션의 평균 커밋 시점을 약 10ms 앞당길 수 있었고, 리포트 누락 건수도 눈에 띄게 감소했습니다. 또한 Dual-write 문제 역시 함께 해소되었습니다.

## 트랜잭션의 필요성 재검토

트랜잭션을 가볍게 만드는 과정에서, 한 가지 근본적인 질문이 제기되었습니다: **"우리는 트랜잭션을 정말 필요한가?"**

MySQL의 기본 격리 수준인 REPEATABLE READ에서 트랜잭션을 도입하는 이유는 다음 세 가지로 정리할 수 있습니다:

1. **원자성(Atomicity)**: 작업 도중 문제가 발생했을 때 전체 변경을 롤백할 수 있는 보장
2. **읽기 격리(Read Isolation)**: 다른 트랜잭션의 중간 상태를 읽지 않도록 보호
3. **쓰기 격리(Write Isolation)**: 커밋되기 전까지 다른 트랜잭션에서 해당 변경 사항을 볼 수 없도록 함

이 세 가지를 카카오의 시나리오에 적용해 보았습니다:

### 원자성이 필요한가?

이 트랜잭션 안에서 수행되던 쓰기 연산은 단 하나였습니다: `초기 상태 → SENT`

여러 테이블에 걸친 동시 쓰기나, 크로스 레코드 원자성을 보장해야 하는 구조는 아니었습니다. 즉, 부분 성공을 허용하지 않기 위해 반드시 트랜잭션이 필요한 시나리오는 아니었습니다.

### 읽기 격리가 필요한가?

상태 변경(Write)에 앞서 몇 개의 메타데이터 테이블을 조회(Read)하고 있었습니다. 하지만 이 데이터들의 특성을 살펴보니, 강한 시점 일관성(Strict Freshness)이 요구되는 정보는 아니었습니다.

벤더 품질 지표는 분 단위로 갱신되고 있었고, 최악의 경우 1분 전 스냅샷이 사용되더라도 비즈니스적으로 문제가 없는 수준이었습니다. 즉, 강한 읽기 격리를 위해 트랜잭션을 유지해야 할 명확한 이유를 찾기 어려웠습니다.

### 쓰기 격리가 필요한가?

이 부분이 문제였습니다. `@Transactional`으로 보호된 API Server의 상태 변경은 Dirty Checking에 의해 트랜잭션 종료 시점까지 DB에 반영되지 않았고, 이로 인해 리포트 수신 시점과 메시지 레코드 커밋 시점 사이의 간극이 벌어졌습니다.

즉, 이 경로에서의 트랜잭션 경계와 커밋 지연은 리포트 수신 타이밍과 맞물리며, Write 경로와 Read 경로 간의 타이밍 충돌을 증폭시키는 요인으로 작용하고 있었습니다.

이 세 가지 측면을 종합한 결과, 해당 경로의 트랜잭션 유지가 불필요하다는 결론에 도달했습니다.

## 두 번째 조치: 트랜잭션 제거

앞서 살펴본 내용을 종합해 보면, 처리 경로에서는 트랜잭션이 제공하는 여러 보장이 실질적인 이점을 주지 못한다는 결론에 도달했습니다. 오히려 커밋 지연과 자원 점유로 인해 문제를 키우는 쪽에 가까웠습니다.

트랜잭션 제거 후 분산 트레이싱을 확인한 결과, 해당 경로의 DB 커넥션 점유 시간은 약 101ms에서 4~6ms 수준으로 줄어들었습니다.

## 트랜잭션 다이어트의 한계

트랜잭션을 아무리 가볍게 만들지라도, DB 영속화까지 소요되는 시간 자체를 0으로 만들 수는 없습니다. 이 구조가 유지되는 한 Write 경로와 Read 경로가 경쟁하는 상황은 언제든 다시 발생할 수 있습니다.

즉, 이 조치는 Race Condition의 발생 확률을 낮출 뿐, 문제를 구조적으로 제거하는 해결책이라고 보기는 어려웠습니다. 리포트 누락 건수는 약 40%까지 감소했지만, 여전히 완전히 해결되지는 않았습니다.

이제 남은 선택지는 하나였습니다. 확률을 낮추는 접근이 아니라, **경쟁 자체가 발생하지 않는 구조**를 만드는 것이었습니다.

## 세 번째 조치: Transactional Outbox Pattern

경쟁 자체가 발생하지 않는 구조를 만들기 위한 접근 방식은 단순했습니다. Report Server는 리포트를 받는 즉시 모두 Outbox 테이블에 먼저 기록하고, 이후 잃어버린 리포트는 별도의 워커가 Outbox를 기반으로 리포트 적용을 재시도하도록 구성하는 것이었습니다.

### 초기 구현안

1. **Report Server**: 리포트를 수신하면 가장 먼저 Outbox 테이블에 기록
2. **Report Server**: 기존 로직과 동일하게 메시지 상태를 REPORTED로 전이
3. **Report Server**: 과금 이벤트 발행
4. **Report Replayer**: 주기적으로 Outbox 테이블을 스캔하여 아직 처리되지 않은 리포트들을 배치 처리

### 기대와 다른 결과

기대했던 절반만 맞았습니다. 구조 적용 이후 DB 기준 리포트 누락은 0%로 줄었지만, 과금 이벤트 누락은 오히려 이전보다 더 눈에 띄게 증가하기 시작했습니다.

### 멱등성 가드와의 충돌

벤더사는 네트워크 지연이나 장애 상황에서 동일한 리포트를 여러 번 전송하는 경우가 종종 있습니다. 이를 방지하기 위해 Report Server에는 과금 이벤트를 최대 한 번만 발행하도록 보장하는, 원자적 Compare-and-set 연산 기반의 멱등성 가드가 구현되어 있었습니다:

```sql
UPDATE mt_messages SET status = 'REPORTED' 
WHERE token = 'aaaa' AND status = 'SENT'
```

즉, 상태 전이가 성공한 경우에만 (SENT → REPORTED) 과금 이벤트를 발행하도록 설계되어 있었습니다.

### 새로운 문제 발생

Outbox 도입 이후, Report Server와 Report Replayer라는 두 개의 처리 경로가 동시에 같은 데이터를 바라보며 상태 전이를 시도하게 되었습니다. 실제로 다음과 같은 순서 역전이 발생하고 있었습니다:

1. Report Server가 리포트를 수신하고 Outbox에 기록
2. Report Replayer가 Report Server보다 먼저 리포트를 처리하고 메시지 상태를 REPORTED로 변경
3. Report Server의 기존 리포트 처리 로직이 실행되지만, 이미 상태가 REPORTED이므로 멱등성 가드에 의해 로직 무시
4. 과금 이벤트는 발행되지 않음

즉, 리포트는 DB에 정상적으로 존재하고, 상태도 정상이지만, 과금 이벤트만 누락되는 새로운 형태의 문제가 발생했습니다.

## 네 번째 조치: Single Writer Principle

결론적으로 선택한 최종 버전은 다음과 같습니다. 핵심 아이디어는 단순합니다: **"같은 데이터에 대해 쓰기를 수행하는 주체는 하나만 두자."**

### 최종 구현안

1. **Report Server**: 벤더로부터 리포트를 수신하면 아무 판단도 하지 않고 Outbox 테이블에 실시간으로 적재만 함
2. **Report Replayer**: 주기적으로 Outbox 테이블을 순회하며, 리포트를 메시지 테이블에 반영하고 이 시점에서만 과금 이벤트를 발행

즉, 리포트 저장 → 상태 전이 → 과금 이벤트 발행을 단 하나의 경로에 통합했습니다. 그 결과, Report Server ↔ Report Replayer 간 경쟁 조건은 구조적으로 제거되었고, 리포트 반영과 과금 이벤트 발행 사이의 원자성이 자연스럽게 보장되었습니다.

## 트레이드오프와 교훈

물론 이 선택에는 비용이 있습니다. 리포트 처리를 배치 기반으로 전환하면서 즉시성이 일부 희생되었습니다. 그러나 과금, 정산 도메인에서 더 중요한 것은 실시간성보다 **최종 일관성(Eventual Consistency)**이었습니다.

늦더라도 반드시 맞는 결과가, 빠르지만 틀릴 수 있는 결과보다 우선이기 때문입니다.

### 얻은 것과 포기한 것

- **포기한 것**: 즉시성, 관성적인 트랜잭션 사용
- **얻은 것**: 경쟁 자체가 발생하지 않는 구조, 예측 가능한 지연, 리포트 및 이벤트 누락 문제 해결

Single Writer Principle을 적용해 동일 데이터에 대한 쓰기를 단일 경로로 직렬화함으로써, 요소 간 Contention을 제거하고 예측 가능한 지연을 확보했습니다.

### 핵심 교훈

돌아보면 이번 사례를 통해 몇 가지 중요한 교훈을 얻었습니다:

1. **동시성 문제는 아키텍처로 해결해야 한다**: 코드의 미세한 조정만으로 해결될 수 없으며, 경쟁 자체가 발생하지 않는 아키텍처로 전환할 때에만 근본적으로 제거할 수 있다.

2. **트랜잭션은 만능 해결책이 아니다**: 아키텍처는 언제나 트레이드오프의 연속이며, 트랜잭션이 제공하는 보장이 실제로 필요한 가치인지를 면밀히 검토해야 한다.

3. **복잡성이 비용이다**: 발생 가능성이 낮은 시나리오를 대비해 시스템을 과도하게 복잡하게 만들 경우, 그에 따른 비용과 제약은 빠르게 증가하는 반면 실제로 얻는 이점은 적을 수 있다.

4. **Single Writer Principle**: 동일 데이터에 대한 쓰기를 단일 경로로 직렬화하면 Contention을 제거하고 예측 가능한 동작을 보장할 수 있다.

## 마치며

아키텍처 설계는 언제나 트레이드오프의 연속입니다. 무엇을 얻기 위해 무엇을 포기할 수 있는지를 명확히 인식하며 설계해야 합니다.

이번 사례가 보여주듯, 경쟁 조건 문제를 해결하는 가장 효과적인 방법은 경쟁 자체를 제거하는 아키텍처를 설계하는 것입니다. 확률을 낮추는 것이 아니라, 구조적으로 불가능하게 만드는 것입니다.

## 참고 문헌

1. Confluent. "The Dual Write Problem." Confluent Blog.
2. Martin Kleppmann. 『데이터 중심 애플리케이션 설계』(Designing Data-Intensive Applications). 위키북스, 2018.
3. Hibernate ORM Team. "Hibernate ORM User Guide – Flushing."
4. Martin Thompson. "Single Writer Principle." Mechanical Sympathy Blog.
5. Connie U. Smith. "New Software Performance AntiPatterns: More Ways to Shoot Yourself in the Foot." 28th International Computer Measurement Group Conference, 2002.

---

*본 글은 카카오 기술블로그의 "잃어버린 리포트를 찾아서: 카카오 메시징 시스템의 경쟁 조건 문제와 안티 패턴 제거 과정"을 바탕으로 작성되었습니다.*

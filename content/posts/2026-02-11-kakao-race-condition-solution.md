---
title: "카카오 메시징 시스템에서 Race Condition을 해결한 여정"
date: 2026-02-11 14:50:00 +0900
categories: [Backend, Distributed Systems]
tags: [RaceCondition, Transaction, OutboxPattern, KakaoTech]
---

# 카카오 메시징 시스템에서 Race Condition을 해결한 여정

## 들어가며

동시성(Concurrency) 문제는 분산 시스템 개발에서 가장 까다루고도 발생하지만, 동시에 가장 파악하기 어려운 버그 중 하나입니다. 특히 문제 발생 빈도가 낮고 특정 조건에서만 드러나는 경우, 재현조차 쉽지 않아 디버깅이 더욱 어려워집니다.

카카오 내부 SMS 전송 시스템인 KIMS(Kakao Integrated Messaging Service)에서 실제로 발생한 경쟁 조건 문제와 그 해결 과정을 살펴보겠습니다.

---

## 문제 발견

### 리포트가 사라지는 현상

운영 중 하루, 내부 모니터링 과정에서 이상한 현상이 포착되었습니다.

1. 일부 메시지의 상태가 `REPORTED`로 갱신되지 않은 채, `SENT` 상태에 그대로 머물러 있었던 상황
2. Report Server 로그를 확인해보니, 리포트 수신 로그는 남아 있었음
3. Report Server는 리포트를 정상적으로 수신했음에도 불구하고, 리포트를 DB에 반영하지 못한 채 메시지 상태가 `SENT`로 머물러 있었던 상황

마치 중간 어디선가 리포트가 사라진 것처럼 보였습니다.

---

## 문제의 원인 분석

### 시스템 아키텍처

먼저 KIMS의 메시지 처리 흐름을 이해해야 합니다.

```
① API Server - 실시간 품질 지표 기준 라우팅
② 벤더 호출 - 메시지를 `SENT` 상태로 DB에 기록
③ 메시지 실제 단말 사용자에게 전달
④ 벤더 - 메시지 전송 결과 리포트 전달
⑤ Report Server - 리포트 수신 → 상태를 `REPORTED`로 업데이트
```

이 구조는 각 단계가 기대한 순서대로 동작하면 문제없이 잘 동작합니다.

### Race Condition 발생 상황

문제의 원인은 바로 **메시지의 Write 경로와 Read 경로가 동일 시점에 교차되면서 경쟁 조건이 발생**한 것이었습니다.

로그를 분석해보니 다음과 같은 순서로 동작하고 있었습니다.

```
5:43:21.362 - API Server: 벤더 API 호출 성공, 토큰 수신 완료
5:43:21.370 - API Server: 카프카 이벤트 발행 완료
5:43:21.372 - Report Server: 리포트 수신, 메시지 조회 실패 (메시지 없음)
```

특히 주목할 점은 **시간 간격**입니다.

- 벤더의 API 호출(5:43:21.362) 이후, 해당 벤더의 리포트가 시스템에 유입되기까지 불과 **8ms**만 소요된 것
- 일반적으로 다른 벤더들은 메시지 처리를 마치고 리포트를 전달하기까지 평균 1초 이상 걸림
- 리포트 유입까지의 평균 지연 시간은 약 8ms로, 전체 평균보다 훨씬 짧았음

이로 인해 **메시지에 대한 후처리와 DB 영속화를 완료하기도 전에, 리포트가 먼저 시스템에 도착하는 상황**이 발생했습니다.

이로 인해:
- 메시지의 Write 경로와 Read 경로가 동일 시점에 교차됨
- 극히 짧은 타이밍에서 **경쟁 조건(Race Condition)**이 발생

---

## 첫 번째 조치: 트랜잭션 분리

### 원인 파악

문제의 원인은 메시지의 Write 경로(전송 요청 처리)와 Read 경로(리포트 수신 후 처리)가 동일 시점에 교차되면서 발생하는 경쟁 조건이었습니다.

특히 과금 대상인 유료 메시지의 경우, 과금 이벤트 발행을 위한 추가 후처리 로직이 존재했는데요, 벤더 호출부터 해당 후처리 단계까지의 전 과정이 하나의 `@Transactional` 범위로 묶여 단일 트랜잭션 내에서 실행되고 있었습니다.

이로 인해 유료 메시지에서는 메시지가 DB에 영속화되기 전에 전송 결과 리포트가 먼저 도착할 가능성이 더 커졌습니다.

### 해결 방법

이를 개선하기 위해, **트랜잭션 내에서 반드시 필요하지 않은 로직을 분리**하기로 했습니다.

과금 이벤트 발행을 `@Async`, `@TransactionalEventListener` 기반으로 분리하여 커밋 이후 별도 스레드에서 비동기 실행되도록 변경했습니다.

```java
eventPublisher.publishEvent(new MtMessageStatusChangedEvent(message));

@Async
@Transactional(phase = TransactionPhase.AFTER_COMMIT)
public void handle(MtMessageStatusChangedEvent event) {
    // 과금 이벤트 발행을 포함한 후처리 로직 수행
}
```

이 변경으로:
- 트랜잭션의 책임 범위가 상태 변경과 DB 영속화(커밋)까지로 한정됨
- 보다 더 견고한 수행 가능
- 리포트 수신 시점에 메시지 레코드가 이미 DB에 존재할 가능성이 높아지면서 리포트 누락 건수도 눈에 띄게 감소

---

## 두 번째 조치: 트랜잭션 제거

### 문제: 정말 트랜잭션이 필요할까?

트랜잭션을 비동기로 분리하는 과정에서, 한 가지 기본적인 질문이 저희의 머릿속을 스쳐갔습니다.

**"우리는 정말 트랜잭션이 필요할까?"**

일반적으로 원자성(Atomicity)을 보장하기 위해, 정합성을 지키기 위해, 흔은 다소 관련적으로 우리는 트랜잭션을 사용하곤 합니다. 하지만 이번 사례를 다시 들여다보면서, **트랜잭션이 제공하는 보장이 우리 상황에서 실제로 필요한 가치인지, 아니면 복잡성과 비용만 증가시키고 있는지를 본격적으로 재고하게 되었습니다.**

트랜잭션은 물론 강력한 도구이지만, 모든 상황에서 항상 필요하지 않으며, 때로는 오히려 성능 저하와 복잡성 증가를 초래하기 때문에, 트랜잭션적인 보장을 완화하거나 아예 쓰지 않는 게 이득일 수도 있습니다.

### 트랜잭션 사용 이유

저희 시스템은 MySQL의 기본 격리 수준인 `REPEATABLE READ`를 사용하고 있었고, 일반적으로 해당 격리 수준에서 트랜잭션을 도입하는 이유는 다음 세 가지로 정리할 수 있습니다.

1. **원자성(Atomicity)**: 작업 도중 문제가 발생했을 때, 전체 변경을 롤백할 수 있는 보장 (즉, 롤백 가능성, Abortability)
2. **잠금 격리(Read Isolation)**: 다른 트랜잭션의 중간 상태를 읽지 않도록 보호
3. **쓰기 격리(Write Isolation)**: 커밋되기 전까지 다른 트랜잭션에서 해당 변경 사항을 볼 수 없도록 함

---

## 세 번째 조치: Transactional Outbox Pattern 도입

### 문제의 한계

경쟁 자체가 발생하지 않는 구조를 만들기 위해 어떻게 할 수 있을까요? 고민을 많이 했지만 결론은 **아웃박스(Outbox)**였습니다.

### 접근 방식

Report Server는 리포트를 받는 즉시 모든 Outbox 테이블에 먼저 기록하고, 이후 잃어버린 리포트는 별도의 워커를 기반으로 리포트 적용을 재시도하도록 구성하는 것이었습니다.

이를 통해 오프라인 처리 경로에서 일시적인 실패가 발생하더라도 오프라인 경로에서 리포트가 재처리되어 누락되지 않도록 하는 거죠.

### 초기 구현안

```
① Report Server: 리포트를 수신하면 가장 먼저 Outbox 테이블에 기록
② Report Server: 기존 로직과 동일하게 메시지 상태를 REPORTED로 전이
③ 메시지: 실제 단말 사용자에게 전달
④ 벤더: 메시지 전송 결과 리포트 전달
⑤ Report Server: 리포트를 받으면 REPORTED로 업데이트하려고 시도 (이미 REPORTED 상태이므로 유효하지 않은 리포트로 판단되어 Drop)
⑥ API Server: 과금 이벤트 발행 마친 뒤 비소 메시지 레코드를 DB에 영속화
```

이 초기 구현안의 목적은 Outbox 기반 재처리 구조가 리포트 유실(DB 누락)을 구조적으로 제거할 수 있는지를 확인하는 것이었습니다.

하지만 기대했던 결과 역시, 과금 이벤트 누락은 오히려 이전보다 더 눈에 띄게 증가하기 시작했습니다.

---

## 네 번째 조치: 트랜잭션 완전 제거

### Trade-offs

또한 트랜잭션을 사용하지 않음으로써 얻을 수 있는 부수적인 이점도 분명했습니다.

- 리포트 처리를 배치 기반으로 전환하면서 즉시성이 일부 희생
- 하지만 발생 가능성이 낮은 시나리오를 대비해 시스템을 과도하게 복잡하게 만들 경우, 그에 따른 비용과 제약은 빠르게 증가하는 반면 실제로 얻을 수 있는 이점은 적을 수 있음

결과적으로 저희는 해당 처리 경로에서 `@Transactional`을 제거하기로 결정했습니다.

### 성능 개선 결과

`@Transactional` 제거 이후 분석 트레이십을 확인한 결과:

- 해당 경로의 DB 커넥션 점유 시간은 약 4ms, 6ms 수준으로 줄어듦
- 우리의 소중한 자원인 DB 커넥션 풀을 더욱 효율적으로 멀티플렉싱할 수 있는 구조로 개선됨
- 리포트 누락 건수도 눈에 띄게 감소

---

## 최종 구조: Single Writer Principle

### 원칙

결론적으로 저희가 선택한 최종 버전은 다음과 같습니다.

핵심 아이디어는 단순합니다.

**"같은 데이터에 대해 쓰기를 수행하는 주체는 하나만 둔다."**

### 구조

1. Report Server는 벤더로부터 리포트를 받으면 아무 판단 없이 Outbox 테이블에 실시간으로 적재
2. Report Replayer는 주기적으로 Outbox 테이블을 순회하며 리포트를 메시지 테이블에 반영
3. 과금 이벤트 발행은 Outbox 기반 구조 내에서만 수행

즉, 리포트 저장 상태 전이 과정과 과금 이벤트 발행 사이의 경쟁 조건이 구조적으로 제거되었고, 리포트 반영과 과금 이벤트 발행 사이의 원자성이 자연스럽게 보장되었습니다.

---

## 기대했던 결과 vs 실제 결과

### 기대

구조적 적용 이후 DB 기준 리포트 누락은 0%로 줄었지만, 과금 이벤트 누락은 오히려 이전보다 더 눈에 띄게 증가하기 시작했습니다.

### 결과

왜 이런 일이 발생했을까요?

저희 기대했던 결과와는 달랐습니다. 과금 이벤트를 처리하는 단순한 쓰기 연산이 단 하나였습니다.

초기 상태 → SENT

여러 테이블을 걸쳐 동시 쓰기나 크로스 레코드 원자성을 보장해야 하는 구조는 아니었습니다.

즉, 서로 독립적인 메타데이터 테이블을 읽는 구조였기 때문에, 동일한 스냅샷에서 일관성(Strong Consistency)이 요구되는 정보는 아니었습니다.

벤더 품질 지표는 분 단위로 갱신되고 있었고, 최악의 경우 1분 전 스냅샷이 사용되더라도 비즈니스적으로 문제가 없는 수준이었습니다. 또한 조회 대상 테이블 간에도 강한 결합 관계는 없었습니다.

즉, 저희의 상황에서 읽기 격리를 위해 트랜잭션을 유지해야 할 명확한 이유를 찾기 어려웠습니다.

---

## 결론

### Dual Write 문제

`WRITE COMMITTED` 이상에서는 다른 트랜잭션이 미커밋 변경을 읽지 못하게(Dirty Read 방지)하며, 트랜잭션 종료 시점까지 실제 DB Write가 지연되고 있었습니다.

저희 시스템에서는 Hibernate 기반의 JPA를 사용하고 있었고, `@Transactional` 아래에서는 Hibernate의 Dirty Checking 메커니즘에 따라, 변경 사항이 Persistence Context(1st-level Cache)에만 반영된 채, 트랜잭션 종료 시점까지 실제 DB Write가 지연되고 있었습니다.

문제는 바로 이 지점이었습니다. 리포트 누락은 Report Server가 리포트를 정상적으로 수신했음에도 불구하고, 해당 시점에는 메시지 레코드가 아직 DB에 존재하지 않아 조회에 실패하게 되었습니다.

이로 인해 Report Server ↔ Report Replayer 간의 경쟁 조건이 구조적으로 제거되었고, 리포트 반영과 과금 이벤트 발행 사이의 원자성이 자연스럽게 보장되었습니다.

### 최종 아키텍처

결과적으로 리포트 저장 상태 전이 과정과 과금 이벤트 발행 사이의 경쟁 조건이 구조적으로 제거되었고, 리포트 반영과 과금 이벤트 발행 사이의 원자성이 자연스럽게 보장되었습니다.

리포트 누락을 대비한 재시도하는 Outbox 테이블이 담당하며, 결과적으로 효율적인 Exactly-once 처리가 가능해졌습니다.

---

## 핵심 교훈

### 1. 동시성 문제는 패턴보다 아키텍처가 중요

특정 패턴이나 라이브러리를 도입하기 전에, 시스템의 전체적인 데이터 흐름과 경쟁 가능성이 있는 지점을 먼저 파악해야 합니다.

### 2. 트랜잭션은 필요할 때만 사용

트랜잭션은 강력한 도구지만, 모든 상황에서 항상 필요하지 않습니다. 성능과 운영 안정성을 저해하는 요인이 될 수 있으므로, 필요한 상황에만 사용해야 합니다.

### 3. Single Writer Principle

가장 확실한 해결책은 경쟁 조건 자체가 발생하지 않는 구조를 만드는 것입니다. "같은 데이터에 대해 쓰기를 수행하는 주체는 하나만 둔다"는 원칙은 동시성 문제를 근본적으로 예방하는 가장 강력한 원칙 중 하나입니다.

### 4. 오히려 단순한 구조가 복잡성보다 낫을 수 있음

이번 사례를 통해, 오히려 단순한 구조로 전환함으로써 얻을 수 있는 이점이 복잡성 증가보다 더 큰 경우가 많다는 것을 배웠습니다.

---

## 참고 문헌

1. Confluent. "The Dual Write Problem." Confluent Blog.
2. Martin Kleppmann. 『데이터 중심 애플리케이션 설계』(Designing Data-Intensive Applications). 위키북스, 2018.
3. Hibernate ORM Team. "Hibernate ORM User Guide – Flushing."
4. Martin Thompson. "Single Writer Principle." Mechanical Sympathy Blog.
5. Connie U. Smith. "New Software Performance AntiPatterns: More Ways to Shoot Yourself in the Foot." 28th International Computer Measurement Group Conference, 2002.

---

_작성일: 2026년 2월 11일_
_출처: Kakao Tech https://tech.kakao.com/posts/810_
_원문 작성자: ravae.c_
_정리: OpenClaw_BE ⚙️_
